{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\LMH\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\lmh23\\AppData\\Local\\Temp\\ipykernel_4512\\2003180911.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"./archive/abcnews-date-text.csv\")\n",
    "data = data[:100000]\n",
    "\n",
    "# Prepare data\n",
    "unpreprocessed_texts = data['headline_text'].tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2)\n",
    "\n",
    "count = vectorizer.fit_transform(unpreprocessed_texts)\n",
    "# processed_texts = vectorizer.transform(unpreprocessed_texts)\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "processed_texts_list = [' '.join(words[doc.nonzero()[1]]) for doc in count]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 500/500 [10:06<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qt = TopicModelDataPreparation(\"all-mpnet-base-v2\")\n",
    "training_dataset = qt.fit(text_for_contextual=unpreprocessed_texts, text_for_bow=processed_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [2/2]\t Seen Samples: [199936/200000]\tTrain Loss: 48.45850321516948\tTime: 0:01:11.062003: : 2it [02:33, 76.90s/it]\n",
      "100%|██████████| 1563/1563 [00:41<00:00, 37.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# CTM\n",
    "n_topics = 10\n",
    "ctm = CombinedTM(bow_size=len(qt.vocab), contextual_size=768, n_components=n_topics, num_epochs=2)\n",
    "\n",
    "# Train CTM with the prepared dataset\n",
    "ctm.fit(training_dataset)\n",
    "ctm_top_words = ctm.get_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ctm_top_words(topic_words, n_topics):\n",
    "    for topic_idx in range(n_topics):\n",
    "        print(\"Topic %d:\" % topic_idx, end=' ')\n",
    "        print(' '.join(topic_words[topic_idx]))\n",
    "        # print('| # topic_count: %d' % ctm.get_topic_count()[topic_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTM Top Words:\n",
      "Topic 0: govt pay act health vic\n",
      "Topic 1: open cup world final tour\n",
      "Topic 2: anderson beckham rann election crean\n",
      "Topic 3: rates farmers drought rain trade\n",
      "Topic 4: court man charged murder trial\n",
      "Topic 5: police killed injured car missing\n",
      "Topic 6: sars china road safety toll\n",
      "Topic 7: iraq war iraqi troops bush\n",
      "Topic 8: cadet unhealthy airlifted sierra somerset\n",
      "Topic 9: council plan indigenous new group\n"
     ]
    }
   ],
   "source": [
    "print(\"CTM Top Words:\")\n",
    "print_ctm_top_words(ctm_top_words, n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lmh23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokenized_texts = [word_tokenize(text) for text in unpreprocessed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['govt pay act health vic', 'open cup world final tour', 'anderson beckham rann election crean', 'rates farmers drought rain trade', 'court man charged murder trial', 'police killed injured car missing', 'sars china road safety toll', 'iraq war iraqi troops bush', 'cadet unhealthy airlifted sierra somerset', 'council plan indigenous new group']\n",
      "Coherence Score: 0.350212131425678\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Dictionary and Coherence Model\n",
    "def get_coherence_score(documents, topics):\n",
    "    dictionary = Dictionary(documents)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "    cm = CoherenceModel(topics=topics, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "    return cm.get_coherence()\n",
    "\n",
    "def get_ctm_topics(model, n_top_words):\n",
    "    topics = []\n",
    "    topic_word_matrix = model.get_topic_lists(n_top_words)\n",
    "    for topic_words in topic_word_matrix:\n",
    "        topics.append(\" \".join(topic_words))\n",
    "    return topics\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print(get_ctm_topics(ctm, 5))\n",
    "print(\"Coherence Score:\", get_coherence_score(tokenized_texts, get_ctm_topics(ctm, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [00:39<00:00, 39.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage for CTM: [0.2068  0.18991 0.3686  0.19378 0.16729 0.18565 0.21838 0.19559 0.24956\n",
      " 0.22758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# coverage for CTM\n",
    "topic_distribution = ctm.get_thetas(training_dataset)\n",
    "\n",
    "topic_presence = (topic_distribution > 0.1).sum(axis=0)\n",
    "coverage = topic_presence / len(training_dataset)\n",
    "\n",
    "print(\"Coverage for CTM:\",coverage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22031399999999998\n"
     ]
    }
   ],
   "source": [
    "print(coverage.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
