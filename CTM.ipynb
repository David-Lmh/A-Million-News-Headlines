{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\LMH\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\lmh23\\AppData\\Local\\Temp\\ipykernel_12456\\767941787.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 500/500 [10:09<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"./archive/abcnews-date-text.csv\")\n",
    "data = data[:100000]\n",
    "\n",
    "# Prepare data\n",
    "unpreprocessed_texts = data['headline_text'].tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2)\n",
    "vectorizer.fit(unpreprocessed_texts)\n",
    "processed_texts = vectorizer.transform(unpreprocessed_texts)\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "processed_texts_list = [' '.join(words[doc.nonzero()[1]]) for doc in processed_texts]\n",
    "\n",
    "\n",
    "qt = TopicModelDataPreparation(\"all-mpnet-base-v2\")\n",
    "training_dataset = qt.fit(text_for_contextual=unpreprocessed_texts, text_for_bow=processed_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [2/2]\t Seen Samples: [199936/200000]\tTrain Loss: 48.520204182623594\tTime: 0:01:13.399499: : 2it [02:27, 73.97s/it]\n",
      "100%|██████████| 1563/1563 [00:42<00:00, 36.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# CTM\n",
    "n_topics = 10\n",
    "ctm = CombinedTM(bow_size=len(qt.vocab), contextual_size=768, n_components=n_topics, num_epochs=2)\n",
    "\n",
    "# Train CTM with the prepared dataset\n",
    "ctm.fit(training_dataset)\n",
    "ctm_top_words = ctm.get_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ctm_top_words(topic_words, n_topics):\n",
    "    for topic_idx in range(n_topics):\n",
    "        print(\"Topic %d:\" % topic_idx, end=' ')\n",
    "        print(' '.join(topic_words[topic_idx]))\n",
    "        # print('| # topic_count: %d' % ctm.get_topic_count()[topic_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTM Top Words:\n",
      "Topic 0: police probe missing search crash\n",
      "Topic 1: iraq iraqi korea baghdad troops\n",
      "Topic 2: council water farmers drought mayor\n",
      "Topic 3: govt funding minister wa indigenous\n",
      "Topic 4: man charged court charges murder\n",
      "Topic 5: england test world cup india\n",
      "Topic 6: qld rail boost coast nsw\n",
      "Topic 7: wall homework hindering psa wessels\n",
      "Topic 8: united injury tigers real liverpool\n",
      "Topic 9: deal trade latham greens pm\n"
     ]
    }
   ],
   "source": [
    "print(\"CTM Top Words:\")\n",
    "print_ctm_top_words(ctm_top_words, n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
